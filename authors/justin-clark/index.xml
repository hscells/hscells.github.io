<<<<<<< HEAD
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Justin Clark | Harry Scells</title>
    <link>/authors/justin-clark/</link>
      <atom:link href="/authors/justin-clark/index.xml" rel="self" type="application/rss+xml" />
    <description>Justin Clark</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu304f1acb77bf86c451cd3e9846c8be03_968531_512x512_fill_lanczos_center_2.png</url>
      <title>Justin Clark</title>
      <link>/authors/justin-clark/</link>
    </image>
    
    <item>
      <title>A Computational Approach for Objectively Derived Systematic Review Search Strategies</title>
      <link>/publication/ecir2020_objective/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/publication/ecir2020_objective/</guid>
      <description>&lt;p&gt;Searching literature for a systematic review begins with a manually constructed search strategy by an expert information specialist. The typical process of constructing search strategies is often undocumented, ad-hoc, and subject to individual expertise, which may introduce bias in the systematic review. A new method for objectively deriving search strategies has arisen from information specialists attempting to address these shortcomings. However, this proposed method still presents a number of manual, ad-hoc interventions, and trial-and-error processes, potentially still introducing bias into systematic reviews. Moreover, this method has not been rigorously evaluated on a large set of systematic review cases, thus its generalisability is unknown. In this work, we present a computational adaptation of this proposed objective method. Our adaptation removes the human-in-the-loop processes involved in the initial steps of creating a search strategy for a systematic review; reducing bias due to human factors and increasing the objectivity of the originally proposed method. Our proposed computational adaptation further enables a formal and rigorous evaluation over a large set of systematic reviews. We find that our computational adaptation of the original objective method provides an effective starting point for information specialists to continue refining. We also identify a number of avenues for extending and improving our adaptation to further promote supporting information specialists.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automatic Boolean Query Formulation for Systematic Review Literature Search</title>
      <link>/publication/www2020_conceptual/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/publication/www2020_conceptual/</guid>
      <description>&lt;p&gt;Formulating Boolean queries for systematic review literature search is a challenging task. Commonly, queries are formulated by information specialists using the protocol specified in the review and interactions with the research team. Information specialists have in-depth experience on how to formulate queries in this domain, but may not have in-depth knowledge about the reviews&#39; topics. Query formulation requires a significant amount of time and effort, and is performed interactively; specialists repeatedly formulate queries, attempt to validate their results, and reformulate specific Boolean clauses. In this paper, we investigate the possibility of automatically formulating a Boolean query from the systematic review protocol. We propose a novel five-step approach to automatic query formulation, specific to Boolean queries in this domain, which approximates the process by which information specialists formulate queries. In this process, we use syntax parsing to derive the logical structure of high-level concepts in a query, automatically extract and map concepts to entities in order to perform entity expansion, and finally apply post-processing operations (such as stemming and search filters).&lt;/p&gt;
&lt;p&gt;Automatic query formulation for systematic review literature search has several benefits: (i) it can provide reviewers with an indication of the types of studies that will be retrieved, without the involvement of an information specialist, (ii) it can provide information specialists with an initial query to begin the formulation process, (iii) it can provide researchers that perform rapid reviews with a method to quickly perform searches.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automatic Boolean Query Refinement for Systematic Review Literature Search</title>
      <link>/publication/cc2019_reformulation/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/publication/cc2019_reformulation/</guid>
      <description>&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube-nocookie.com/embed/A1GtoNFWN0c&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt; 
&lt;p&gt;Background: Within the last decade the rise of digital publishing has become widespread, enabling publications to be edited and updated after-the-fact. In the medical domain, systematic reviews are one type of digital document that is often updated after initial publication. This is usually because new evidence has been discovered and must be re-synthesised into the existing review. A problem, however, is that the initial search strategy used to identify the originally relevant studies may not be sufficient in capturing new studies, or may capture too many irrelevant studies. This means that time and effort must be spent reformulating new or variant search strategies. While this problem may be particularly pronounced in “living systematic reviews”, the problem of finding all relevant studies while minimising irrelevant studies for typical systematic reviews is also difficult. This overarching problem signifies a gap to be filled with a system for automatic search strategy reformulation.&lt;/p&gt;
&lt;p&gt;Objectives: The development of an automatic, interactive search strategy reformulation tool that assists researchers in updating systematic reviews and to improve existing search strategies.&lt;/p&gt;
&lt;p&gt;Methods: The system proposed uses a recognised and effective theoretical framework which automatically generates search strategy reformulations and selects the most effective variation. In this work, a user interface (Figure 1) is developed with the goal to insert a human-in-the-loop to drive the selection of the most effective search strategy. This interface is capable of: (i) tracking the effectiveness of reformulations over time, allowing users to manage their reformulation history by backtracking and jumping to previous search strategies, (ii) evaluating the effectiveness of reformulations using standard Information Retrieval measures (e.g., precision, recall, F-measure), and domain-specific evaluation measures (e.g., Work Saved) by loading in a validation set of studies, and (iii) filtering out studies which have already been screened (also by loading separately) in order to only show new studies.&lt;/p&gt;
&lt;p&gt;Results: The theoretical framework for which the generation and selection of search strategy reformulations is based on is shown to significantly improve the effectiveness of existing queries. Queries are shown to increase in effectiveness upwards of 100-200% and beyond depending on the automatic selection process and evaluation measure.&lt;/p&gt;
&lt;p&gt;Conclusions: A human-in-the-loop for the selection of search strategy reformulation allows users to have fine-grained control over the reformulation process. Allowing humans to drive the selection process in this framework is a new and novel approach, which has not yet been attempted. Finally, automatically generating reformulations removes possible human bias and error, and reduces the time and effort required to update a review.&lt;/p&gt;
&lt;p&gt;Patient or healthcare consumer involvement: This has no direct involvement with patients or consumers, although improved efficiency of systematic review searches could be beneficial to both groups.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualising Systematic Review Search Strategies to Assist Information Specialists</title>
      <link>/publication/cc2019_visualisation/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/publication/cc2019_visualisation/</guid>
      <description>&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube-nocookie.com/embed/HPEQWCrMGWw&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Background: Searching for studies to include in systematic reviews involves the construction of complex search strategies. The effectiveness of these search strategies directly impacts the workload associated with conducting a systematic review. More efficient search strategies can reduce the time and resources required to screen studies therefore reducing the total time and cost of the review. Research in Information Retrieval (IR) shows that query visualisation improves the effectiveness of searching for information.&lt;/p&gt;
&lt;p&gt;Objectives: The development of a visualisation tool that assists information specialists in formulating more effective search strategies.&lt;/p&gt;
&lt;p&gt;Methods: The visualisation tool (QueryVis) is designed in collaboration with information specialists to cater to the needs of this user group. Currently in QueryVis, it is possible to visualise search strategies using the PubMed database. Searches can be submitted in Ovid MEDLINE format or PubMed format (by automatically translating the Ovid format to PubMed). QueryVis presents queries hierarchically (Figure 1) , showing the impact that each term has on the recall and precision of a search. Recall is shown by the number of studies retrieved from a validation set, loaded via PubMed IDs. Precision is shown by total number of studies found by each term. Search strategies are compared in terms of the overlap in search terms between two searches, the total number of keywords, the total number of each Boolean operator (i.e., AND, OR, NOT), the number of MeSH keywords (and how many are exploded), and the depth in the MeSH ontology in which the MeSH keywords appear (i.e., how broad MeSH keywords are). Furthermore, each search is evaluated in terms of effectiveness: using standard IR evaluation measures (i.e., precision, recall, F-measure) and evaluation measures specific to this domain (e.g., Work Saved), and in terms of efficiency: by recording the total time spent formulating, the number of studies retrieved, and the estimated cost of the search.&lt;/p&gt;
&lt;p&gt;Results: QueryVis has been tested experimentally in a pilot study. It decreased irrelevant studies by as much as 40% without losing relevant studies. A wider study is planned which aims to involve more participants and capture more data.&lt;/p&gt;
&lt;p&gt;Conclusions: Improving the query formulation stage can have a significant impact on the rest of the systematic review creation process. An extensive user study will follow using a well-known corpus of systematic reviews with approximately 10 participants to determine precisely what effect visualisation has on the search strategy formulation process. The study will use the aforementioned methods to compare the effect visualisation has on search by comparing search strategies formulated with and without visualisation. If accepted for publication, QueryVis will be demoed during the oral presentation.&lt;/p&gt;
&lt;p&gt;Patient or healthcare consumer involvement: This has no direct involvement with patients or consumers, although improved efficiency of systematic review searches could be beneficial to both groups.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
=======
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Justin Clark | Harry Scells</title><link>/authors/justin-clark/</link><atom:link href="/authors/justin-clark/index.xml" rel="self" type="application/rss+xml"/><description>Justin Clark</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate><image><url>/media/icon_hu304f1acb77bf86c451cd3e9846c8be03_968531_512x512_fill_lanczos_center_3.png</url><title>Justin Clark</title><link>/authors/justin-clark/</link></image><item><title>From Little Things Big Things Grow: A Collection with Seed Studies for Medical Systematic Review Literature Search</title><link>/publication/sigir2022_seed/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>/publication/sigir2022_seed/</guid><description>&lt;p>Fine-grained logging of interactions in user studies is important for studying user behaviour, among other reasons. However, in many research scenarios, the way interactions are logged are usually tied to a monolithic system. We present a generic, application-independent service for logging interactions in web-pages, specifically targetting user studies. Our service, Big Brother, can be dropped-in to existing user interfaces with almost no configuration required by researchers. Big Brother has already been used in several user studies to record interactions in a number of user study research scenarios, such as lab-based and crowdsourcing environments. We further demonstrate the ability for Big Brother to scale to very large user studies through benchmarking experiments. Big Brother also provides a number of additional tools for visualising and analysing interactions.&lt;/p>
&lt;p>Big Brother significantly lowers the barrier to entry for logging user interactions by providing a minimal but powerful, no configuration necessary, service for researchers and practitioners of user studies that can scale to thousands of concurrent sessions. We have made the source code and releases for Big Brother available for download at &lt;a href="https://github.com/hscells/bigbro" target="_blank" rel="noopener">https://github.com/hscells/bigbro&lt;/a>.&lt;/p></description></item><item><title>A Computational Approach for Objectively Derived Systematic Review Search Strategies</title><link>/publication/ecir2020_objective/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>/publication/ecir2020_objective/</guid><description>&lt;p>Searching literature for a systematic review begins with a manually constructed search strategy by an expert information specialist. The typical process of constructing search strategies is often undocumented, ad-hoc, and subject to individual expertise, which may introduce bias in the systematic review. A new method for objectively deriving search strategies has arisen from information specialists attempting to address these shortcomings. However, this proposed method still presents a number of manual, ad-hoc interventions, and trial-and-error processes, potentially still introducing bias into systematic reviews. Moreover, this method has not been rigorously evaluated on a large set of systematic review cases, thus its generalisability is unknown. In this work, we present a computational adaptation of this proposed objective method. Our adaptation removes the human-in-the-loop processes involved in the initial steps of creating a search strategy for a systematic review; reducing bias due to human factors and increasing the objectivity of the originally proposed method. Our proposed computational adaptation further enables a formal and rigorous evaluation over a large set of systematic reviews. We find that our computational adaptation of the original objective method provides an effective starting point for information specialists to continue refining. We also identify a number of avenues for extending and improving our adaptation to further promote supporting information specialists.&lt;/p></description></item><item><title>Automatic Boolean Query Formulation for Systematic Review Literature Search</title><link>/publication/www2020_conceptual/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>/publication/www2020_conceptual/</guid><description>&lt;p>Formulating Boolean queries for systematic review literature search is a challenging task. Commonly, queries are formulated by information specialists using the protocol specified in the review and interactions with the research team. Information specialists have in-depth experience on how to formulate queries in this domain, but may not have in-depth knowledge about the reviews' topics. Query formulation requires a significant amount of time and effort, and is performed interactively; specialists repeatedly formulate queries, attempt to validate their results, and reformulate specific Boolean clauses. In this paper, we investigate the possibility of automatically formulating a Boolean query from the systematic review protocol. We propose a novel five-step approach to automatic query formulation, specific to Boolean queries in this domain, which approximates the process by which information specialists formulate queries. In this process, we use syntax parsing to derive the logical structure of high-level concepts in a query, automatically extract and map concepts to entities in order to perform entity expansion, and finally apply post-processing operations (such as stemming and search filters).&lt;/p>
&lt;p>Automatic query formulation for systematic review literature search has several benefits: (i) it can provide reviewers with an indication of the types of studies that will be retrieved, without the involvement of an information specialist, (ii) it can provide information specialists with an initial query to begin the formulation process, (iii) it can provide researchers that perform rapid reviews with a method to quickly perform searches.&lt;/p></description></item><item><title>Automatic Boolean Query Refinement for Systematic Review Literature Search</title><link>/publication/cc2019_reformulation/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>/publication/cc2019_reformulation/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/A1GtoNFWN0c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;p>Background: Within the last decade the rise of digital publishing has become widespread, enabling publications to be edited and updated after-the-fact. In the medical domain, systematic reviews are one type of digital document that is often updated after initial publication. This is usually because new evidence has been discovered and must be re-synthesised into the existing review. A problem, however, is that the initial search strategy used to identify the originally relevant studies may not be sufficient in capturing new studies, or may capture too many irrelevant studies. This means that time and effort must be spent reformulating new or variant search strategies. While this problem may be particularly pronounced in “living systematic reviews”, the problem of finding all relevant studies while minimising irrelevant studies for typical systematic reviews is also difficult. This overarching problem signifies a gap to be filled with a system for automatic search strategy reformulation.&lt;/p>
&lt;p>Objectives: The development of an automatic, interactive search strategy reformulation tool that assists researchers in updating systematic reviews and to improve existing search strategies.&lt;/p>
&lt;p>Methods: The system proposed uses a recognised and effective theoretical framework which automatically generates search strategy reformulations and selects the most effective variation. In this work, a user interface (Figure 1) is developed with the goal to insert a human-in-the-loop to drive the selection of the most effective search strategy. This interface is capable of: (i) tracking the effectiveness of reformulations over time, allowing users to manage their reformulation history by backtracking and jumping to previous search strategies, (ii) evaluating the effectiveness of reformulations using standard Information Retrieval measures (e.g., precision, recall, F-measure), and domain-specific evaluation measures (e.g., Work Saved) by loading in a validation set of studies, and (iii) filtering out studies which have already been screened (also by loading separately) in order to only show new studies.&lt;/p>
&lt;p>Results: The theoretical framework for which the generation and selection of search strategy reformulations is based on is shown to significantly improve the effectiveness of existing queries. Queries are shown to increase in effectiveness upwards of 100-200% and beyond depending on the automatic selection process and evaluation measure.&lt;/p>
&lt;p>Conclusions: A human-in-the-loop for the selection of search strategy reformulation allows users to have fine-grained control over the reformulation process. Allowing humans to drive the selection process in this framework is a new and novel approach, which has not yet been attempted. Finally, automatically generating reformulations removes possible human bias and error, and reduces the time and effort required to update a review.&lt;/p>
&lt;p>Patient or healthcare consumer involvement: This has no direct involvement with patients or consumers, although improved efficiency of systematic review searches could be beneficial to both groups.&lt;/p></description></item><item><title>Visualising Systematic Review Search Strategies to Assist Information Specialists</title><link>/publication/cc2019_visualisation/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>/publication/cc2019_visualisation/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/HPEQWCrMGWw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;p>Background: Searching for studies to include in systematic reviews involves the construction of complex search strategies. The effectiveness of these search strategies directly impacts the workload associated with conducting a systematic review. More efficient search strategies can reduce the time and resources required to screen studies therefore reducing the total time and cost of the review. Research in Information Retrieval (IR) shows that query visualisation improves the effectiveness of searching for information.&lt;/p>
&lt;p>Objectives: The development of a visualisation tool that assists information specialists in formulating more effective search strategies.&lt;/p>
&lt;p>Methods: The visualisation tool (QueryVis) is designed in collaboration with information specialists to cater to the needs of this user group. Currently in QueryVis, it is possible to visualise search strategies using the PubMed database. Searches can be submitted in Ovid MEDLINE format or PubMed format (by automatically translating the Ovid format to PubMed). QueryVis presents queries hierarchically (Figure 1) , showing the impact that each term has on the recall and precision of a search. Recall is shown by the number of studies retrieved from a validation set, loaded via PubMed IDs. Precision is shown by total number of studies found by each term. Search strategies are compared in terms of the overlap in search terms between two searches, the total number of keywords, the total number of each Boolean operator (i.e., AND, OR, NOT), the number of MeSH keywords (and how many are exploded), and the depth in the MeSH ontology in which the MeSH keywords appear (i.e., how broad MeSH keywords are). Furthermore, each search is evaluated in terms of effectiveness: using standard IR evaluation measures (i.e., precision, recall, F-measure) and evaluation measures specific to this domain (e.g., Work Saved), and in terms of efficiency: by recording the total time spent formulating, the number of studies retrieved, and the estimated cost of the search.&lt;/p>
&lt;p>Results: QueryVis has been tested experimentally in a pilot study. It decreased irrelevant studies by as much as 40% without losing relevant studies. A wider study is planned which aims to involve more participants and capture more data.&lt;/p>
&lt;p>Conclusions: Improving the query formulation stage can have a significant impact on the rest of the systematic review creation process. An extensive user study will follow using a well-known corpus of systematic reviews with approximately 10 participants to determine precisely what effect visualisation has on the search strategy formulation process. The study will use the aforementioned methods to compare the effect visualisation has on search by comparing search strategies formulated with and without visualisation. If accepted for publication, QueryVis will be demoed during the oral presentation.&lt;/p>
&lt;p>Patient or healthcare consumer involvement: This has no direct involvement with patients or consumers, although improved efficiency of systematic review searches could be beneficial to both groups.&lt;/p></description></item></channel></rss>
>>>>>>> a97c381dd957cd8e6b5ed781f1aad54d7d3c56ac
