[{"authors":["Harrisen Scells","Daniel Locke","Guido Zuccon"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"fea346ebc9abe69f4c000de4d4e682f0","permalink":"/publication/sigir2018_framework/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/sigir2018_framework/","section":"publication","summary":"","tags":null,"title":"An Information Retrieval Experiment Framework for Domain Specific Applications","type":"publication"},{"authors":["Harrisen Scells","Guido Zuccon"],"categories":null,"content":"Systematic reviews form the cornerstone of evidence based medicine, aiming to answer complex medical questions based on all evidence currently available. Key to the effectiveness of a systematic review is an (often large) Boolean query used to search large publication repositories. These Boolean queries are carefully crafted by researchers and information specialists, and often reviewed by a panel of experts. However, little is known about the effectiveness of the Boolean queries at the time of formulation.\nIn this paper we investigate whether a better Boolean query than that defined in the protocol of a systematic review, can be created, and we develop methods for the transformation of a given Boolean query into a more effective one. Our approach involves defining possible transformations of Boolean queries and their clauses. It also involves casting the problem of identifying a transformed query that is better than the original into: (i) a classification problem; and (ii) a learning to rank problem. Empirical experiments are conducted on a real set of systematic reviews. Analysis of results shows that query transformations that are better than the original queries do exist, and that our approaches are able to select more effective queries from the set of possible transformed queries so as to maximise different target effectiveness measures.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"a947b6d3f3c6fb81f3f69baa46440b25","permalink":"/publication/sigir2018_generating/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/sigir2018_generating/","section":"publication","summary":"Systematic reviews form the cornerstone of evidence based medicine, aiming to answer complex medical questions based on all evidence currently available. Key to the effectiveness of a systematic review is an (often large) Boolean query used to search large publication repositories. These Boolean queries are carefully crafted by researchers and information specialists, and often reviewed by a panel of experts. However, little is known about the effectiveness of the Boolean queries at the time of formulation.","tags":null,"title":"Generating Better Queries for Systematic Reviews","type":"publication"},{"authors":["Harrisen Scells","Leif Azzopardo","Guido Zuccon","Bevan Koopman"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"dd453e0e1ea6994c202341721bf20891","permalink":"/publication/sigir2018_qvpp/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/sigir2018_qvpp/","section":"publication","summary":"","tags":null,"title":"Query Variation Performance Prediction for Systematic Reviews","type":"publication"},{"authors":["Harrisen Scells","Guido Zuccon"],"categories":null,"content":"We present an open source tool, searchrefiner, for researchers that conduct medical systematic reviews to assist in formulating, visualising, and understanding Boolean queries. The searchrefiner web interface allows researchers to explore how Boolean queries retrieve citations in existing, popular query syntaxes used in systematic review literature search. The web interface allows researchers to perform tasks such as using validation citations to ensure queries are retrieving a minimum set of known relevant citations, and editing Boolean queries by dragging and dropping clauses in a structured editor. In addition, the tools provided by the searchrefiner interface allow researchers to visualise why the queries they formulate retrieve citations, and ways to understand how to refine queries into more effective ones. searchrefiner is targeted at both experts and novices, as a tool for query formulation and refinement, and as a tool for training users to search for literature to compile systematic reviews.\nThe searchrefiner website located at https://ielab.io/searchrefiner contains information about how to download, install, and use the tool, as well as a link to an online hosted version for demonstration purposes.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536705627,"objectID":"71672abfbd12c9b62c64ba2cd97d8e80","permalink":"/publication/cikm2018_searchrefiner/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/cikm2018_searchrefiner/","section":"publication","summary":"We present an open source tool, searchrefiner, for researchers that conduct medical systematic reviews to assist in formulating, visualising, and understanding Boolean queries. The searchrefiner web interface allows researchers to explore how Boolean queries retrieve citations in existing, popular query syntaxes used in systematic review literature search. The web interface allows researchers to perform tasks such as using validation citations to ensure queries are retrieving a minimum set of known relevant citations, and editing Boolean queries by dragging and dropping clauses in a structured editor.","tags":null,"title":"searchrefiner: A Query Visualisation and Understanding Tool for Systematic Reviews","type":"publication"},{"authors":["Harrisen Scells","Guido Zuccon","Bevan Koopman","Anthony Deacon","Leif Azzopardi","Shlomo Geva"],"categories":null,"content":"We introduce a test collection for evaluating the effectiveness of different methods used to retrieve research studies for inclusion in systematic reviews. Systematic reviews appraise and synthesise studies that meet specific inclusion criteria. Systematic reviews intended for a biomedical science audience use boolean queries with many, often complex, search clauses to retrieve studies; these are then manually screened to determine eligibility for inclusion in the review. This process is expensive and time consuming. The development of systems that improve retrieval effectiveness will have an immediate impact by reducing the complexity and resources required for this process. Our test collection consists of approximately 26 million research studies extracted from the freely available MEDLINE database, 94 review (query) topics extracted from Cochrane systematic reviews, and corresponding relevance assessments. Tasks for which the collection can be used for information retrieval system evaluation are described and the use of the collection to evaluate common baselines within one such task is demonstrated. See the links to this side of this page for links to the paper and to download the collection.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"6c0e3aaf8f594b1eb00f4c9c2a0e6d18","permalink":"/publication/sigir2017_collection/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/sigir2017_collection/","section":"publication","summary":"We introduce a test collection for evaluating the effectiveness of different methods used to retrieve research studies for inclusion in systematic reviews. Systematic reviews appraise and synthesise studies that meet specific inclusion criteria. Systematic reviews intended for a biomedical science audience use boolean queries with many, often complex, search clauses to retrieve studies; these are then manually screened to determine eligibility for inclusion in the review. This process is expensive and time consuming.","tags":null,"title":"A Test Collection for Evaluating Retrieval of Studies for Inclusion in Systematic Reviews","type":"publication"},{"authors":["Harrisen Scells","Guido Zuccon","Anthony Deacon","Bevan Koopman"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"deb1d81846ccf16b85206880807430df","permalink":"/publication/cikm2017_pico/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cikm2017_pico/","section":"publication","summary":"","tags":null,"title":"Integrating the Framing of Clinical Questions via PICO into the Retrieval of Medical Literature for Systematic Reviews","type":"publication"},{"authors":["Harrisen Scells","Guido Zuccon","Anthony Deacon","Bevan Koopman"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"cd3effd36f4d48b7b9b4c4c098581960","permalink":"/publication/clef2017_tar/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/clef2017_tar/","section":"publication","summary":"","tags":null,"title":"QUT ielab at CLEF eHealth 2017 Technology Assisted Reviews Track: Initial Experiments with Learning To Rank","type":"publication"},{"authors":["Harrisen Scells"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"49b8e6178b2cc93b148e1217c530ed9e","permalink":"/publication/fdia2017_essir/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/fdia2017_essir/","section":"publication","summary":"","tags":null,"title":"Reducing Workload of Systematic Review Searching and Screening Processes","type":"publication"},{"authors":["Harrisen Scells"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"ec7b0da516eb00a93e6cf9d104c6151c","permalink":"/publication/honours_thesis/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/honours_thesis/","section":"publication","summary":"","tags":null,"title":"Investigating Methods Of Annotating Lifelogs For Use In Search","type":"publication"},{"authors":["Harrisen Scells","Guido Zuccon","Kirsty Kitto"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536198062,"objectID":"33375a45bb0c59c630907a831b587a0d","permalink":"/publication/ntcir2016_lifelog/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/ntcir2016_lifelog/","section":"publication","summary":"","tags":null,"title":"QUT at the NTCIR Lifelog Semantic Access Task","type":"publication"}]